{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cac504c-2dcf-434b-8977-be95b3d31d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import os \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = open('/Users/spangher/.openai-bloomberg-project-key.txt').read().strip()\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def prompt_openai(prompt, model='gpt-4o-mini'):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29be57e7-1587-4fe1-8a38-5442d7ab4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the things that the science article mentions that we didn't. Do you want to do deeper in any of them?\n",
    "# Here are images from the file and a description of each\n",
    "# Do you want to know more about the image? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f20ab1-942f-46cc-9d16-84c7e621cef4",
   "metadata": {},
   "source": [
    "# News Article/Science Article Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5453c3f8-a973-48f7-9ef6-bf3963d199d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERALL_CONTENT_DIFF_PROMPT = \"\"\"\n",
    "You are a fun and descriptive helper who helps me interpret science articles. Here is the text of a scientific article\n",
    "\n",
    "<science_article>\n",
    "{science_article}\n",
    "</science_article>\n",
    "\n",
    "Here is a news article the New York Times wrote based on the scientific article:\n",
    "\n",
    "<news_article>\n",
    "{news_article}\n",
    "</news_article>\n",
    "\n",
    "Write a 100 word paragraph from the New York Times' perspective summarizing the angle they took on the science article.\n",
    "In a new paragraph, give a 100-word high-level summary of the information that's in the science article that \n",
    "they chose not to cover directly in the news article.\n",
    "\n",
    "Be descriptive and informative, but also be approachable. Use plain English, don't use overly flowery language. \n",
    "\n",
    "This is intended for a general audience.\n",
    "\n",
    "Your response:\n",
    "\"\"\"\n",
    "\n",
    "CONTENT_ITEMS_DIFF_PROMPT = \"\"\"\n",
    "You are a fun and descriptive helper who helps me interpret science articles.\n",
    "\n",
    "Here is the text of a scientific article\n",
    "\n",
    "<science_article>\n",
    "{science_article}\n",
    "</science_article>\n",
    "\n",
    "Here is a news article that is written off of the scientific article:\n",
    "\n",
    "<news_article>\n",
    "{news_article}\n",
    "</news_article>\n",
    "\n",
    "Describe the content that is in the scientific article but not the news article. \n",
    "Group each category of content separately (e.g. \"Description of Methods\", \"Background\", etc.)\n",
    "Be descriptive and informative, but also be approachable. Use plain English, don't use overly flowery language, \n",
    "and explain the significance of each content type in the science aritcle. \n",
    "This is intended for a general audience. \n",
    "\n",
    "Return this as a JSON with keys being the categories of information and a description of the content differences for each category. \n",
    "Return just the JSON, nothing else.\n",
    "\n",
    "Your response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f5501a-ffd2-49f3-ba70-e0426bb04471",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df_with_files = pd.read_json('../data/science_articles-with-parsed-files.json.gz', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ee44150-6510-4385-8f7a-1f3c5cd7f98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaaed9e1785e4aee972cce067c06e678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RUN_OVERALL_SUMMARY = True\n",
    "RUN_SPECIFIC_CONTENT_DIFF = True\n",
    "content_diff_summary_output = []\n",
    "all_specific_content_diff_output = []\n",
    "for _, row in tqdm(science_df_with_files.iterrows(), total=len(science_df_with_files)):\n",
    "    while True:\n",
    "        science_file_text = open(row['txt_file']).read().strip()\n",
    "        news_article_text = row['bodyText']\n",
    "        ##############################################################\n",
    "        if RUN_OVERALL_SUMMARY:\n",
    "            ## overall summary\n",
    "            overall_diff_summ = prompt_openai(\n",
    "                OVERALL_CONTENT_DIFF_PROMPT.format(\n",
    "                    news_article=news_article_text,\n",
    "                    science_article=science_file_text                \n",
    "                ), model='gpt-4.1'\n",
    "            )\n",
    "            content_diff_summary_output.append(overall_diff_summ)\n",
    "        ##############################################################\n",
    "        if RUN_SPECIFIC_CONTENT_DIFF:\n",
    "            try:\n",
    "                ## specific pieces of items \n",
    "                content_diff_output = prompt_openai(\n",
    "                    CONTENT_ITEMS_DIFF_PROMPT.format(\n",
    "                        news_article=news_article_text,\n",
    "                        science_article=science_file_text\n",
    "                    ), model='gpt-4.1'\n",
    "                )\n",
    "                content_diff_output = content_diff_output.replace('```json', '').replace('```', '')\n",
    "    \n",
    "                parsed = json.loads(content_diff_output)\n",
    "                all_specific_content_diff_output.append({\n",
    "                    'id': row['id'],\n",
    "                    'output': parsed\n",
    "                })\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f'error: {str(e)}')\n",
    "                pass\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "367569d0-ca6b-4dc5-a9bf-4be4936f8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df_with_files['diff_summary'] = content_diff_summary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4cb5e08-b0b4-4ae0-b552-77f4821c88c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In their coverage, The New York Times focused on the clever ways spiders adapt to urban noise by engineering their webs to suit their noisy surroundings. They highlighted the spiders’ use of webs both as amplifiers and mufflers of sound—a blend of hearing aid and noise-canceling headphones. The story zeroed in on how urban spiders soften vibrations to tune out constant clamors, while rural spiders boost sensitivity during sudden noise spikes. The article drew broad parallels to human strategies for coping with noise, and emphasized the ability of spiders to rapidly adjust their behavior in response to their environment.\n",
      "\n",
      "The original scientific article takes a deeper dive into the technical and experimental aspects of the research. It explains the experimental design—how spiders from both rural and urban backgrounds were raised under controlled “loud” or “quiet” vibratory conditions and how researchers measured exactly how vibrations travel across the webs. The study examined specifics like which frequency ranges are relevant for spider prey capture, differences in web silk properties, and how changes in web-building may be driven by genetic or developmental factors. The paper also discusses potential ecological consequences, touches on evolutionary implications, and lays out ideas for future research into animal sensory flexibility.\n"
     ]
    }
   ],
   "source": [
    "print(content_diff_summary_output[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52126727-2ec4-45d3-8b17-38c8060b0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/output_data/v3_science_diff.json', 'w') as f:\n",
    "    json.dump(all_specific_content_diff_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96245100-2bd6-4a1c-8840-9819e870978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/output_data/science_diff_summaries.json', 'w') as f:\n",
    "    json.dump(content_diff_summary_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d3bea394-c452-4f96-8d19-32af659e0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df_with_files[['id', 'diff_summary']].to_json('../app/app_data/diffs_summaries.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8b96b8cc-7f41-4221-b1f0-176e360c5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_specific_content_diff_output_copy = []\n",
    "for o in all_specific_content_diff_output:\n",
    "    content = o['output']\n",
    "    new_output = {}\n",
    "    for k, v in content.items():\n",
    "        if isinstance(v, dict):\n",
    "            v = v['content']\n",
    "        new_output[k] = v\n",
    "    all_specific_content_diff_output_copy.append({\n",
    "        'id': o['id'],\n",
    "        'output': new_output\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9316a1fe-bb68-4091-800b-370db5a7bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_specific_content_diff_output_copy).to_json('../app/app_data/diffs_specific_categories.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135f7e8-3d1e-440f-8815-6ddd917eb054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06c6fe-a27b-47c4-919e-077887d11508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0331e6b2-cf82-4952-abba-16ac25c77d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c5e06-bab4-4a3e-9c44-a91b2832c6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f611783-5faf-4840-a93d-3f10fb4b019a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22f2f0a5-4fe5-486b-a298-34f036e26e09",
   "metadata": {},
   "source": [
    "# Describe Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f5bba03-a9af-4cc4-a0c4-00b86b2f6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image_mapper = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f5dfca2-c21d-4751-b017-2d4404b406a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTION_PROMPT = \"\"\"\n",
    "This image is from the following scientific article.\n",
    "\n",
    "<science_article>\n",
    "{science_article}\n",
    "</science_article>\n",
    "\n",
    "Can you do the follow:\n",
    "1. \"Caption\": Please caption this image for a general audience. Use plain English. Be descriptive. Describe what it shows.\n",
    "2. \"Significance\": Please describe why the authors used this image.\n",
    "3. \"Fun fact\": Please note a fun fact about the image that you notice. Make it fun an engaging!\n",
    "\n",
    "Return your response as a JSON. Say nothing else.\n",
    "\n",
    "Your response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77bbd00-d949-43cf-9353-d2a9c134d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_output = []\n",
    "for _, row in tqdm(science_df_with_files.iterrows(), total=len(science_df_with_files)):\n",
    "    science_article_text = open(row['txt_file']).read().strip()\n",
    "    img_path = '../data/found-science-articles/figures'\n",
    "    folder_name = os.path.basename(row['pdf_file'].replace('.pdf', ''))\n",
    "    images = glob.glob(f'{img_path}/{folder_name}/*')\n",
    "    images = list(filter(lambda x: '.pdf' not in x, images))\n",
    "    \n",
    "    for i in images:\n",
    "        image = Image.open(i)\n",
    "        if image.mode in (\"RGBA\", \"P\"):\n",
    "            image = image.convert(\"RGB\")\n",
    "        image.save(i.replace('.png', '.pdf').replace('.jpg', '.pdf'), \"PDF\")\n",
    "\n",
    "    pdf_images = glob.glob(f'{img_path}/{folder_name}/*.pdf')\n",
    "    uploaded_file_ids = []\n",
    "    for f in tqdm(pdf_images):\n",
    "        file = client.files.create(\n",
    "            file=open(f, \"rb\"),\n",
    "            purpose=\"user_data\"\n",
    "        )\n",
    "        uploaded_file_ids.append({\n",
    "            'id': os.path.basename(f),\n",
    "            'openai_id': file.id\n",
    "        })\n",
    "\n",
    "    for uploaded_image in tqdm(uploaded_file_ids):\n",
    "        prompt = CAPTION_PROMPT.format(science_article=science_article_text)\n",
    "        while True:\n",
    "            output = prompt_openai_with_files(prompt, uploaded_image['openai_id'])\n",
    "            output = output.replace('```json', '').replace('```', '')\n",
    "            try:\n",
    "                parsed = json.loads(output)\n",
    "                all_image_output.append({\n",
    "                    'id': row['id'],\n",
    "                    'image_id': uploaded_image['id'],\n",
    "                    'output': parsed\n",
    "                })\n",
    "                break\n",
    "            except:\n",
    "                print('failed, trying again...')\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51dc76e-0d36-4d62-8f01-3bbacd5cbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_output = list(filter(lambda x: 'image_id' in x, all_output))\n",
    "with open('../data/output_data/image_output_data.json', 'w') as f:\n",
    "    json.dump(all_image_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57478fdf-e493-46ac-b9d8-a26b3f501ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_image_output).to_json('../app/app_data/image_descriptions.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51ebbf0f-1e3d-4be9-a0e5-0c9ae21cec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df_with_files[['id', 'headline', 'bylines', 'bodyText']].to_json(path_or_buf='../app/app_data/science_article_sample.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b2e41dfd-b4af-4a3b-ac90-b57f45b3e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_folder_mapper = (\n",
    "    science_df_with_files\n",
    "         .assign(image_file_name=lambda df: df['file'].str.split('/').str.get(-1).str.replace('.pdf', ''))\n",
    "         [['id', 'image_file_name']]\n",
    "         .set_index('id')['image_file_name'].to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72331e2d-69a4-41c9-b303-26d3551ec1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../app/app_data/article_id_folder_mapper.json', 'w') as f:\n",
    "    json.dump(id_folder_mapper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13da5381-9027-480f-acc1-201e8b6819ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcompositionality-in-bonobos\u001b[m\u001b[m/     \u001b[34mshingles-vaccine\u001b[m\u001b[m/\n",
      "\u001b[34mfoie-gras-without-force-feeding\u001b[m\u001b[m/ \u001b[34mstentor-colonies\u001b[m\u001b[m/\n",
      "\u001b[34mfunnel-web-spiders\u001b[m\u001b[m/              \u001b[34mwarty-birch-caterpillars\u001b[m\u001b[m/\n",
      "\u001b[34mground-sloths-extinct-species\u001b[m\u001b[m/   \u001b[34mwater-abundance-moon\u001b[m\u001b[m/\n",
      "\u001b[34mmedieval-manuscripts\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls ../app/app_data/science_article_figures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffee4db-be41-4511-9dfd-793d1c030ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f830df-fbfb-43ef-b0c0-eb322263bfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c68fb0-d10f-492f-8740-74818b5d88be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
